{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SST Predition Project\n",
    "- 海表温度 (SST)\n",
    "- 这个文件作为一个简单开始，搭建一个简单的预测框架，仅利用ERA5的数据"
   ],
   "id": "2082b13df3f66504"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.708644Z",
     "start_time": "2025-05-22T08:04:09.697100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 验证cuda安装成功\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ],
   "id": "27973de4982d2492",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.800340Z",
     "start_time": "2025-05-22T08:04:09.781438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 0: 全局配置和导入\n",
    "# -----------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- 数据相关配置 ---\n",
    "DATA_DIR = '../data/ERA5/'\n",
    "START_DATE_STR = '2020-01-01'\n",
    "END_DATE_STR = '2020-03-31' # 可以调整为更长的时间范围以获得更多数据\n",
    "FILE_PREFIX = ''\n",
    "FILE_SUFFIX = '_ERA5_daily_mean_sst.nc'\n",
    "FILENAME_DATE_FORMAT = '%Y%m%d'\n",
    "\n",
    "VARIABLE_NAME = 'sst'\n",
    "LATITUDE_POINT = 30.0\n",
    "LONGITUDE_POINT = 120.0\n",
    "\n",
    "# --- 模型相关配置 ---\n",
    "LOOK_BACK = 15          # 使用过去N天的数据 (如果数据量少，尝试减小此值)\n",
    "PREDICT_STEPS = 1       # 预测未来N天\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "# --- 训练相关配置 ---\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 16         # 如果数据量少，尝试减小此值\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_SPLIT_RATIO = 0.8 # 80% 训练, 20% 测试\n",
    "BEST_MODEL_PATH = 'model/best_sst_model.pth'\n",
    "\n",
    "# --- 设备配置 ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- 随机种子 ---\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"设置随机种子以保证结果可复现\"\"\"\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "set_seed(SEED)"
   ],
   "id": "d8f96b8e83048ac6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.846650Z",
     "start_time": "2025-05-22T08:04:09.803833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 1: 数据处理模块\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def get_file_paths_in_range(data_dir, start_date_str, end_date_str,\n",
    "                            file_prefix, file_suffix, date_format):\n",
    "    \"\"\"获取指定日期范围内的所有NetCDF文件路径列表\"\"\"\n",
    "    start_dt = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "    end_dt = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "    \n",
    "    file_paths = []\n",
    "    current_dt = start_dt\n",
    "    while current_dt <= end_dt:\n",
    "        date_str_in_filename = current_dt.strftime(date_format)\n",
    "        filename = f\"{file_prefix}{date_str_in_filename}{file_suffix}\"\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            file_paths.append(file_path)\n",
    "        else:\n",
    "            print(f\"警告: 文件 {file_path} 未找到，将被跳过。\")\n",
    "        current_dt += timedelta(days=1)\n",
    "        \n",
    "    if not file_paths:\n",
    "        print(f\"错误: 在目录 '{data_dir}' 中未找到 {start_date_str} 到 {end_date_str} 范围内的任何文件。\")\n",
    "        return None\n",
    "    file_paths.sort()\n",
    "    return file_paths\n",
    "\n",
    "def load_and_preprocess_sst_data(file_paths, lat, lon, var_name):\n",
    "    \"\"\"加载并预处理SST数据\"\"\"\n",
    "    if not file_paths:\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        print(f\"找到 {len(file_paths)} 个文件，将使用 xarray.open_mfdataset 进行合并。\")\n",
    "        ds_combined = xr.open_mfdataset(file_paths, combine='by_coords', engine='netcdf4')\n",
    "        \n",
    "        print(\"\\n合并后的数据集信息:\")\n",
    "        print(ds_combined)\n",
    "\n",
    "        sst_series_xr = ds_combined[var_name].sel(latitude=lat, longitude=lon, method='nearest')\n",
    "        \n",
    "        time_coords = sst_series_xr['time'].values\n",
    "        sst_values = sst_series_xr.values\n",
    "\n",
    "        if sst_series_xr.attrs.get('units', '').lower() == 'k':\n",
    "            sst_values = sst_values - 273.15\n",
    "            print(\"SST数据已从开尔文转换为摄氏度。\")\n",
    "\n",
    "        sst_df = pd.Series(sst_values)\n",
    "        nan_count = sst_df.isnull().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"数据中发现 {nan_count} 个NaN值，将使用前向填充然后后向填充处理。\")\n",
    "            sst_df = sst_df.fillna(method='ffill').fillna(method='bfill')\n",
    "            sst_values = sst_df.values\n",
    "            if pd.Series(sst_values).isnull().sum() > 0:\n",
    "                raise ValueError(\"处理后仍存在NaN值，请检查数据源。\")\n",
    "        \n",
    "        min_required_length = LOOK_BACK + PREDICT_STEPS + BATCH_SIZE # 至少需要一个batch用于测试\n",
    "        if len(sst_values) < min_required_length:\n",
    "             print(f\"警告: 数据点较少 ({len(sst_values)}), 最小需求约为 {min_required_length}。可能不足以进行有效的训练和测试。\")\n",
    "             if len(sst_values) <= LOOK_BACK + PREDICT_STEPS:\n",
    "                 raise ValueError(f\"数据点 ({len(sst_values)}) 过少，无法满足 look_back和predict_steps的要求。\")\n",
    "        return sst_values, time_coords\n",
    "    except Exception as e:\n",
    "        print(f\"加载或处理数据时发生错误: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def preview_raw_data(sst_values, time_coords, lat, lon, start_date_str, end_date_str):\n",
    "    \"\"\"预览原始SST数据\"\"\"\n",
    "    if sst_values is None or len(sst_values) == 0:\n",
    "        print(\"无有效SST数据，无法进行预览。\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    if time_coords is not None and len(time_coords) == len(sst_values):\n",
    "        plt.plot(time_coords, sst_values, label=f'SST at ({lat}, {lon})')\n",
    "        plt.xlabel('日期 (Date)')\n",
    "    else:\n",
    "        plt.plot(sst_values, label=f'SST at ({lat}, {lon})')\n",
    "        plt.xlabel('时间步 (Time Step)')\n",
    "    plt.title(f'原始SST时间序列预览 ({start_date_str} to {end_date_str})')\n",
    "    plt.ylabel('SST (°C)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def scale_data(sst_values):\n",
    "    \"\"\"归一化数据\"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    sst_scaled = scaler.fit_transform(sst_values.reshape(-1, 1))\n",
    "    return sst_scaled, scaler\n",
    "\n",
    "def create_sequences(data, look_back, predict_steps):\n",
    "    \"\"\"创建时间序列样本\"\"\"\n",
    "    X, y = [], []\n",
    "    if len(data) < look_back + predict_steps:\n",
    "        print(f\"数据长度 {len(data)} 不足以创建 look_back={look_back}, predict_steps={predict_steps} 的序列。\")\n",
    "        return np.array(X), np.array(y)\n",
    "    for i in range(len(data) - look_back - predict_steps + 1):\n",
    "        X.append(data[i:(i + look_back), 0])\n",
    "        y.append(data[(i + look_back):(i + look_back + predict_steps), 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def split_and_prepare_data(X_data, y_data, train_split_ratio, batch_size, look_back):\n",
    "    \"\"\"划分数据并创建DataLoader\"\"\"\n",
    "    if X_data.size == 0 or y_data.size == 0:\n",
    "        print(\"未能从数据中创建任何训练/测试序列。\")\n",
    "        return None, None, None, None # train_loader, test_loader, X_test_tensor, y_test_tensor\n",
    "\n",
    "    split_index = int(len(X_data) * train_split_ratio)\n",
    "    \n",
    "    # 确保训练集和测试集有足够的数据，特别是对于小数据集\n",
    "    min_samples_for_test = max(1, batch_size // 2) # 测试集至少有 batch_size/2 个样本或1个\n",
    "    if len(X_data) - split_index < min_samples_for_test : # 如果测试集样本太少\n",
    "        if len(X_data) > look_back + min_samples_for_test : # 确保总数据量足够划分\n",
    "            split_index = len(X_data) - min_samples_for_test # 调整分割点，给测试集留足样本\n",
    "            print(f\"调整了训练/测试分割点，以确保测试集至少有 {min_samples_for_test} 个样本。新的分割索引：{split_index}\")\n",
    "        else:\n",
    "            print(\"警告：总数据量过少，无法划分出有意义的测试集。将使用所有数据进行训练，评估将不可靠。\")\n",
    "            split_index = len(X_data) # 所有数据用于训练\n",
    "\n",
    "    if split_index == 0 and len(X_data) > 0: # 如果训练集为空\n",
    "        print(\"警告：计算得到的训练集为空，将尝试调整。\")\n",
    "        if len(X_data) > min_samples_for_test: # 如果总数据多于最小测试样本\n",
    "            split_index = len(X_data) - min_samples_for_test\n",
    "        elif len(X_data) > 0: # 如果总数据少于最小测试，但仍有数据\n",
    "            split_index = len(X_data) # 全用于训练\n",
    "        else: # 没数据了\n",
    "            print(\"错误：没有序列数据可用于训练。\")\n",
    "            return None, None, None, None\n",
    "            \n",
    "    X_train, X_test = X_data[:split_index], X_data[split_index:]\n",
    "    y_train, y_test = y_data[:split_index], y_data[split_index:]\n",
    "\n",
    "    print(f\"训练集序列数: {len(X_train)}, 测试集序列数: {len(X_test)}\")\n",
    "\n",
    "    if len(X_train) == 0:\n",
    "        print(\"错误：训练集为空，无法继续。\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    X_train_tensor = torch.from_numpy(X_train).float().unsqueeze(-1)\n",
    "    y_train_tensor = torch.from_numpy(y_train).float()\n",
    "    train_dataset = SSTDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    X_test_tensor, y_test_tensor, test_loader = None, None, None\n",
    "    if len(X_test) > 0:\n",
    "        X_test_tensor = torch.from_numpy(X_test).float().unsqueeze(-1)\n",
    "        y_test_tensor = torch.from_numpy(y_test).float()\n",
    "        test_dataset = SSTDataset(X_test_tensor, y_test_tensor)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        print(\"警告: 测试集为空。模型将仅在训练数据上训练，无法进行独立验证或最终评估。\")\n",
    "\n",
    "    return train_loader, test_loader, X_test_tensor, y_test_tensor"
   ],
   "id": "2f6730e1e5101d4e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.876078Z",
     "start_time": "2025-05-22T08:04:09.857307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 2: 模型定义模块\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class SSTDataset(Dataset):\n",
    "    \"\"\"自定义SST数据集\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM模型\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # Dropout只在num_layers > 1时应用于LSTM层之间\n",
    "        lstm_dropout = dropout_rate if num_layers > 1 else 0\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=lstm_dropout)\n",
    "        # 可以在全连接层前加一个Dropout\n",
    "        # self.dropout = nn.Dropout(dropout_rate) \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # out = self.dropout(out[:, -1, :]) # 应用dropout\n",
    "        out = self.fc(out[:, -1, :]) # 只取序列中最后一个时间步的输出来进行预测\n",
    "        return out"
   ],
   "id": "26ead5b1f2544240",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.906094Z",
     "start_time": "2025-05-22T08:04:09.880085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 3: 训练模块\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def train_model_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    \"\"\"执行一个epoch的训练\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in data_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def validate_model_epoch(model, data_loader, criterion, device):\n",
    "    \"\"\"执行一个epoch的验证\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    if data_loader is None or len(data_loader) == 0:\n",
    "        return float('nan') # 或其他表示不可用的值\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def run_training_loop(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, best_model_path):\n",
    "    \"\"\"运行完整的训练循环\"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    print(\"\\n开始训练模型...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_train_loss = train_model_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        avg_val_loss = validate_model_epoch(model, val_loader, criterion, device) # val_loader可能是test_loader\n",
    "        val_losses.append(avg_val_loss) # 即使是NaN也记录下来\n",
    "\n",
    "        val_loss_str = f\"{avg_val_loss:.6f}\" if not np.isnan(avg_val_loss) else \"N/A (无验证集)\"\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {val_loss_str}\")\n",
    "\n",
    "        if not np.isnan(avg_val_loss) and avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"  验证损失改善，模型已保存至 {best_model_path}\")\n",
    "        elif np.isnan(avg_val_loss) and ((epoch + 1) % 10 == 0 or (epoch + 1) == num_epochs): # 无验证集时定期保存\n",
    "            fallback_model_path = f\"sst_model_epoch_{epoch+1}.pth\"\n",
    "            torch.save(model.state_dict(), fallback_model_path)\n",
    "            print(f\"  模型已保存至 {fallback_model_path} (无验证，按轮次保存)\")\n",
    "            \n",
    "    print(\"训练完成!\")\n",
    "    return train_losses, val_losses"
   ],
   "id": "42f724075cab912e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.936643Z",
     "start_time": "2025-05-22T08:04:09.909573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 4: 评估模块\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, scaler, best_model_path):\n",
    "    \"\"\"在测试集上评估模型\"\"\"\n",
    "    if test_loader is None or len(test_loader) == 0:\n",
    "        print(\"\\n无测试数据，跳过模型评估。\")\n",
    "        return None, None, float('nan')\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        print(f\"\\n已加载最佳模型 {best_model_path} 进行评估...\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"警告: 未找到最佳模型文件 {best_model_path}。将使用当前模型状态进行评估 (可能不是最佳)。\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型时出错: {e}。将使用当前模型状态进行评估。\")\n",
    "        \n",
    "    model.eval()\n",
    "    all_test_predictions_scaled = []\n",
    "    all_test_actuals_scaled = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X_test, batch_y_test in test_loader:\n",
    "            batch_X_test = batch_X_test.to(device)\n",
    "            predictions_scaled = model(batch_X_test)\n",
    "            all_test_predictions_scaled.append(predictions_scaled.cpu().numpy())\n",
    "            all_test_actuals_scaled.append(batch_y_test.numpy()) # y已经是cpu tensor\n",
    "\n",
    "    if not all_test_predictions_scaled: # 如果测试集为空或未能进行预测\n",
    "        print(\"未能生成测试集预测。\")\n",
    "        return None, None, float('nan')\n",
    "\n",
    "    test_predictions_s = np.concatenate(all_test_predictions_scaled)\n",
    "    test_actuals_s = np.concatenate(all_test_actuals_scaled)\n",
    "    \n",
    "    test_predictions_orig = scaler.inverse_transform(test_predictions_s)\n",
    "    test_actuals_orig = scaler.inverse_transform(test_actuals_s)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(test_actuals_orig, test_predictions_orig))\n",
    "    print(f\"测试集均方根误差 (RMSE): {rmse:.4f} °C\")\n",
    "    \n",
    "    return test_predictions_orig, test_actuals_orig, rmse"
   ],
   "id": "632b11c33564a938",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:09.982230Z",
     "start_time": "2025-05-22T08:04:09.940048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 5: 可视化模块\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    \"\"\"绘制训练和验证损失曲线\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='训练损失 (Training Loss)')\n",
    "    # 过滤掉NaN的验证损失值再绘图\n",
    "    val_losses_filtered = [v for v in val_losses if not np.isnan(v)]\n",
    "    if val_losses_filtered:\n",
    "        plt.plot(range(len(train_losses) - len(val_losses_filtered), len(train_losses)), # 确保对齐\n",
    "                 val_losses_filtered, label='验证损失 (Validation Loss)')\n",
    "    plt.title('模型训练和验证损失')\n",
    "    plt.xlabel('迭代次数 (Epoch)')\n",
    "    plt.ylabel('损失 (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_predictions(test_actuals_orig, test_predictions_orig, predict_steps, y_test_len_before_concat):\n",
    "    \"\"\"绘制测试集上的预测 vs 真实值\"\"\"\n",
    "    if test_actuals_orig is None or test_predictions_orig is None:\n",
    "        print(\"无测试结果可供绘制。\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    # y_test_len_before_concat 是原始y_test的长度，用于生成正确的x轴标签\n",
    "    time_steps_test_plot = np.arange(y_test_len_before_concat)\n",
    "\n",
    "\n",
    "    if predict_steps == 1:\n",
    "        plt.plot(time_steps_test_plot, test_actuals_orig.flatten()[:y_test_len_before_concat], label='真实SST (Actual Test SST)', color='blue')\n",
    "        plt.plot(time_steps_test_plot, test_predictions_orig.flatten()[:y_test_len_before_concat], label='预测SST (Predicted Test SST)', color='red', linestyle='--')\n",
    "    else: # 多步预测，只画第一步\n",
    "        plt.plot(time_steps_test_plot, test_actuals_orig[:y_test_len_before_concat, 0], label='真实SST (Actual Test SST - Step 1)', color='blue')\n",
    "        plt.plot(time_steps_test_plot, test_predictions_orig[:y_test_len_before_concat, 0], label='预测SST (Predicted Test SST - Step 1)', color='red', linestyle='--')\n",
    "    \n",
    "    plt.title(f'测试集SST预测 vs 真实值 (未来 {predict_steps} 天)')\n",
    "    plt.xlabel(f'测试集样本索引') # X轴现在是测试集样本的索引\n",
    "    plt.ylabel('SST (°C)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions_on_original(original_sst_values, original_time_coords,\n",
    "                                 test_predictions_orig, test_actuals_orig,\n",
    "                                 split_index_in_sequences, look_back, predict_steps):\n",
    "    \"\"\"将测试集预测叠加在原始数据图上\"\"\"\n",
    "    if test_predictions_orig is None or test_actuals_orig is None:\n",
    "        print(\"无测试预测结果，无法绘制叠加图。\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    \n",
    "    # 绘制原始数据\n",
    "    if original_time_coords is not None and len(original_time_coords) == len(original_sst_values):\n",
    "        plt.plot(original_time_coords, original_sst_values, label='原始SST数据', color='grey', alpha=0.7)\n",
    "        x_axis_is_time = True\n",
    "    else:\n",
    "        plt.plot(original_sst_values, label='原始SST数据', color='grey', alpha=0.7)\n",
    "        x_axis_is_time = False\n",
    "\n",
    "    # 计算测试集预测在原始数据图上的起始点\n",
    "    # 第一个测试序列的第一个输入点对应原始数据的 sst_values[split_index_in_sequences]\n",
    "    # 该序列的目标 (y) 对应原始数据的 sst_values[split_index_in_sequences + look_back]\n",
    "    overlay_start_index_for_target = split_index_in_sequences + look_back\n",
    "    \n",
    "    num_predictions_to_plot = len(test_predictions_orig)\n",
    "    \n",
    "    # 确保不越界\n",
    "    if overlay_start_index_for_target + num_predictions_to_plot > len(original_sst_values):\n",
    "        num_predictions_to_plot = len(original_sst_values) - overlay_start_index_for_target\n",
    "\n",
    "    if num_predictions_to_plot <= 0:\n",
    "        print(\"警告：无法在原始数据图上叠加测试集预测，可能是索引计算问题或数据太少。\")\n",
    "    else:\n",
    "        # 准备用于绘图的预测数据（只取第一步预测）\n",
    "        predictions_to_plot = test_predictions_orig[:num_predictions_to_plot, 0] if predict_steps > 1 else test_predictions_orig[:num_predictions_to_plot].flatten()\n",
    "        \n",
    "        if x_axis_is_time:\n",
    "            time_for_predictions = original_time_coords[overlay_start_index_for_target : overlay_start_index_for_target + num_predictions_to_plot]\n",
    "            if len(time_for_predictions) == len(predictions_to_plot):\n",
    "                 plt.plot(time_for_predictions, predictions_to_plot, label=f'测试集预测 (Step 1)', color='red', linestyle='-')\n",
    "            else: # Fallback\n",
    "                 print(\"时间坐标与预测数据长度不匹配，绘图可能不准确。\")\n",
    "                 plt.plot(np.arange(overlay_start_index_for_target, overlay_start_index_for_target + num_predictions_to_plot),\n",
    "                     predictions_to_plot, label=f'测试集预测 (Step 1, approx.)', color='red', linestyle='-')\n",
    "\n",
    "        else: # x轴是索引\n",
    "            plt.plot(np.arange(overlay_start_index_for_target, overlay_start_index_for_target + num_predictions_to_plot),\n",
    "                     predictions_to_plot, label=f'测试集预测 (Step 1)', color='red', linestyle='-')\n",
    "        \n",
    "        # 标记测试集开始位置\n",
    "        if x_axis_is_time and overlay_start_index_for_target < len(original_time_coords):\n",
    "            plt.axvline(x=original_time_coords[overlay_start_index_for_target], color='green', linestyle='--', label=f'测试集预测开始')\n",
    "        elif not x_axis_is_time:\n",
    "             plt.axvline(x=overlay_start_index_for_target, color='green', linestyle='--', label=f'测试集预测开始')\n",
    "\n",
    "\n",
    "    plt.title('SST预测叠加在原始数据上')\n",
    "    plt.xlabel('日期 (Date)' if x_axis_is_time else '时间步 (原始数据索引)')\n",
    "    plt.ylabel('SST (°C)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "518abec3545d1903",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:04:10.122179Z",
     "start_time": "2025-05-22T08:04:09.985586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块 6: 主执行流程\n",
    "# -----------------------------------------------------------------------------\n",
    "def main():\n",
    "    \"\"\"主执行函数\"\"\"\n",
    "    print(\"--- 开始SST预测流程 ---\")\n",
    "\n",
    "    # 1. 数据加载和预处理\n",
    "    print(\"\\n--- 1. 数据加载和预处理 ---\")\n",
    "    file_paths = get_file_paths_in_range(DATA_DIR, START_DATE_STR, END_DATE_STR,\n",
    "                                         FILE_PREFIX, FILE_SUFFIX, FILENAME_DATE_FORMAT)\n",
    "    if not file_paths:\n",
    "        print(\"未能获取文件路径，程序退出。\")\n",
    "        return\n",
    "\n",
    "    sst_values, time_coords = load_and_preprocess_sst_data(file_paths, LATITUDE_POINT, LONGITUDE_POINT, VARIABLE_NAME)\n",
    "    if sst_values is None:\n",
    "        print(\"未能加载SST数据，程序退出。\")\n",
    "        return\n",
    "\n",
    "    preview_raw_data(sst_values, time_coords, LATITUDE_POINT, LONGITUDE_POINT, START_DATE_STR, END_DATE_STR)\n",
    "    \n",
    "    sst_scaled, scaler = scale_data(sst_values)\n",
    "    \n",
    "    X_sequences, y_sequences = create_sequences(sst_scaled, LOOK_BACK, PREDICT_STEPS)\n",
    "    if X_sequences.size == 0:\n",
    "        print(\"未能创建序列数据，程序退出。\")\n",
    "        return\n",
    "    \n",
    "    # 记录分割前X_sequences的长度，用于后续计算叠加图的起始索引\n",
    "    num_original_sequences = len(X_sequences)\n",
    "\n",
    "    train_loader, test_loader, X_test_tensor, y_test_tensor = split_and_prepare_data(\n",
    "        X_sequences, y_sequences, TRAIN_SPLIT_RATIO, BATCH_SIZE, LOOK_BACK\n",
    "    )\n",
    "\n",
    "    if train_loader is None:\n",
    "        print(\"未能准备训练数据加载器，程序退出。\")\n",
    "        return\n",
    "    \n",
    "    # 计算测试集在原始序列中的起始索引，用于后续绘图\n",
    "    # split_index_in_sequences = len(X_sequences) - (len(X_test_tensor) if X_test_tensor is not None else 0)\n",
    "    # 上面的计算方式不准确，因为split_index是基于len(X_data)*TRAIN_SPLIT_RATIO\n",
    "    # 更准确的是，如果train_loader.dataset.X是X_train_tensor\n",
    "    split_index_in_sequences = len(train_loader.dataset.X) if hasattr(train_loader.dataset, 'X') else int(num_original_sequences * TRAIN_SPLIT_RATIO)\n",
    "\n",
    "\n",
    "    # 2. 模型初始化\n",
    "    print(\"\\n--- 2. 模型初始化 ---\")\n",
    "    model = LSTMModel(input_size=1, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS,\n",
    "                      output_size=PREDICT_STEPS, dropout_rate=DROPOUT_RATE).to(DEVICE)\n",
    "    print(model)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # 3. 模型训练\n",
    "    print(\"\\n--- 3. 模型训练 ---\")\n",
    "    # 注意：这里我们将test_loader作为验证集传入训练循环\n",
    "    train_losses, val_losses = run_training_loop(model, train_loader, test_loader, criterion, optimizer,\n",
    "                                                 NUM_EPOCHS, DEVICE, BEST_MODEL_PATH)\n",
    "    plot_losses(train_losses, val_losses)\n",
    "\n",
    "    # 4. 模型评估\n",
    "    print(\"\\n--- 4. 模型评估 ---\")\n",
    "    # y_test_tensor 是未经过DataLoader处理的完整测试集标签，用于绘图时获取原始测试集长度\n",
    "    y_test_len_for_plot = len(y_test_tensor) if y_test_tensor is not None else 0\n",
    "\n",
    "    test_predictions_orig, test_actuals_orig, rmse = evaluate_model(\n",
    "        model, test_loader, criterion, DEVICE, scaler, BEST_MODEL_PATH\n",
    "    )\n",
    "    \n",
    "    # 5. 结果可视化 (只有在评估成功后才进行)\n",
    "    if test_predictions_orig is not None and test_actuals_orig is not None:\n",
    "        print(\"\\n--- 5. 结果可视化 ---\")\n",
    "        plot_test_predictions(test_actuals_orig, test_predictions_orig, PREDICT_STEPS, y_test_len_for_plot)\n",
    "        \n",
    "        plot_predictions_on_original(sst_values, time_coords,\n",
    "                                     test_predictions_orig, test_actuals_orig,\n",
    "                                     split_index_in_sequences, LOOK_BACK, PREDICT_STEPS)\n",
    "    else:\n",
    "        print(\"由于评估未成功或无测试数据，跳过部分结果可视化。\")\n",
    "\n",
    "    print(\"\\n--- SST预测流程结束 ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "8a255370a59d2958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始SST预测流程 ---\n",
      "\n",
      "--- 1. 数据加载和预处理 ---\n",
      "找到 91 个文件，将使用 xarray.open_mfdataset 进行合并。\n",
      "加载或处理数据时发生错误: [Errno -101] NetCDF: HDF error: 'D:\\\\SCUT\\\\Second Year\\\\Second Semester\\\\地理所Project\\\\SST_Prediciton\\\\data\\\\ERA5\\\\20200101_ERA5_daily_mean_sst.nc'\n",
      "未能加载SST数据，程序退出。\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:15:34.888284Z",
     "start_time": "2025-05-22T09:15:34.754458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "root_dir = \"D:\\\\SCUT\\\\Second Year\\\\Second Semester\\\\地理所Project\\\\SST_Prediciton\"\n",
    "file = os.path.join(root_dir,\"data/ERA5/20200101_ERA5_daily_mean_sst.nc\")\n",
    "try:\n",
    "    dt = xr.open_dataset(file)\n",
    "    print(dt.info())\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "id": "29bc7698314893d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno -101] NetCDF: HDF error: 'D:\\\\SCUT\\\\Second Year\\\\Second Semester\\\\地理所Project\\\\SST_Prediciton\\\\data\\\\ERA5\\\\20200101_ERA5_daily_mean_sst.nc'\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55dcaea3995cecb7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
